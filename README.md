<!-- PROJECT LOGO -->
<p align="center">
  
  <h1 align="center">Any Fashion Attribute Editing: Dataset and Pretrained Models</h1>
  <p align="center">
    <a href="https://github.com/FST-ZHUSHUMIN/"><strong>Shumin Zhu</strong></a>
    ·    
    <a href="https://github.com/AemikaChow/"><strong>Xingxing Zou</strong></a>
    ·
    <a href="https://github.com/flyywh"><strong>Wenhan Yang</strong></a>
    ·
    <a href="https://www.aidlab.hk/en/people-detail/prof-calvin-wong"><strong>Waikeung Wong</strong></a>
  </p>
  <h2 align="center">TPAMI 2025</h2>

  <div align="center">
    <img src="./Why.jpg" alt="Why" width="100%">
  </div>
  
    Our main contributions are as follows:

$\bullet$  We present the Any Fashion Editing Dataset (AFED), which contains 830K high-quality full-body fashion images from two domains.

$\bullet$ We propose Twin-Net, a GAN-based framework for high-quality fashion image inversion and editing.

$\bullet$ We design PairsPCA, a method that is capable of mining the clear mapping relationship between latent and semantic meanings consistently. 

<br />

## Quick View
This work focuses on `any' fashion attribute editing: 1) the ability to edit 78 fine-grained design attributes commonly observed in daily life; 2) the capability to modify desired attributes while keeping the rest components still; and 3) the flexibility to continuously edit on the edited image. Comprehensive experiments, including comparisons with ten state-of-the-art image inversion methods and four editing algorithms, demonstrate the effectiveness of our Twin-Net and editing algorithm.

  <div align="center">
    <img src="./more_all.jpg" alt="Logo" width="100%">
  </div>



## How to Use



## Citation
```bib

```

<br>


<br>
